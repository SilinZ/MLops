{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37pny5jGNiTi",
        "outputId": "ebc01b87-03dd-4b4e-b984-74dfbb0f3857"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "已创建或确认存在目录：/content/drive/MyDrive/MLops\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# 1. 挂载你的 Google Drive 到 /content/drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. 在 MyDrive 下创建 MLops 文件夹\n",
        "mlops_path = '/content/drive/MyDrive/MLops'\n",
        "os.makedirs(mlops_path, exist_ok=True)\n",
        "\n",
        "print(f\"已创建或确认存在目录：{mlops_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# We are using a newer version of tensorflow-privacy (0.9.0) that is compatible\n",
        "# with the newer tensorflow-probability (0.22.1) and tensorflow (2.15.0).\n",
        "!pip install --upgrade tensorflow==2.15.0 tensorflow-estimator==2.15.0 keras==2.15.0 tensorflow-privacy==0.9.0 tensorflow-probability==0.22.1 numpy==1.26.4\n",
        "\n",
        "# IMPORTANT: This will automatically restart the Colab runtime after installation.\n",
        "# The \"Session crashed\" message is expected and necessary.\n",
        "import os\n",
        "print(\"\\n✅ Final installation of all specific versions complete. The runtime will now restart.\")\n",
        "os.kill(os.getpid(), 9)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHFja8mejsPp",
        "outputId": "b1f3df50-44ec-4d9c-af13-fed2f5bf119b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: keras==2.15.0 in /usr/local/lib/python3.11/dist-packages (2.15.0)\n",
            "Requirement already satisfied: tensorflow-privacy==0.9.0 in /tmp/tf_privacy (0.9.0)\n",
            "Requirement already satisfied: tensorflow-probability==0.22.1 in /usr/local/lib/python3.11/dist-packages (0.22.1)\n",
            "Requirement already satisfied: numpy==1.26.4 in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.14.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (22.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.25.8)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (4.14.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (0.37.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (1.73.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.15.0) (2.15.2)\n",
            "Requirement already satisfied: dm-tree==0.1.8 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (0.1.8)\n",
            "Requirement already satisfied: dp-accounting==0.4.4 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (0.4.4)\n",
            "Requirement already satisfied: scikit-learn==1.*,>=1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.6.1)\n",
            "Requirement already satisfied: scipy~=1.9 in /usr/local/lib/python3.11/dist-packages (from tensorflow-privacy==0.9.0) (1.15.3)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.22.1) (4.4.2)\n",
            "Requirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow-probability==0.22.1) (3.1.1)\n",
            "Requirement already satisfied: attrs>=22 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.4->tensorflow-privacy==0.9.0) (25.3.0)\n",
            "Requirement already satisfied: mpmath~=1.2 in /usr/local/lib/python3.11/dist-packages (from dp-accounting==0.4.4->tensorflow-privacy==0.9.0) (1.3.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn==1.*,>=1.0->tensorflow-privacy==0.9.0) (3.6.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.45.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.8.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from tensorflow_privacy.privacy.analysis import compute_dp_sgd_privacy"
      ],
      "metadata": {
        "id": "YsxW-oODnhdn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 切到项目根\n",
        "%cd /content/drive/MyDrive/MLops\n",
        "\n",
        "# 2. 初始化 Git & 安装 Git LFS\n",
        "!git init -q\n",
        "!apt-get update -y -qq && apt-get install git-lfs -y -qq\n",
        "!git lfs install\n",
        "\n",
        "# 3. 初始化 DVC（无 SCM 模式，用本地文件夹当 remote）\n",
        "!pip install -q dvc\n",
        "!dvc init --no-scm\n",
        "!mkdir -p dvc_store\n",
        "!dvc remote add -d local_remote /content/drive/MyDrive/MLops/dvc_store\n",
        "\n",
        "# 4. v1：版本管理原始数据（Git LFS + DVC）\n",
        "!mkdir -p data/raw data/clean models metrics\n",
        "!mv athletes.csv data/raw/athletes.csv\n",
        "!git lfs track \"data/raw/athletes.csv\"\n",
        "!git add .gitattributes\n",
        "!dvc add data/raw/athletes.csv\n",
        "!git add data/raw/athletes.csv.dvc\n",
        "!git commit -m \"v1: track raw athletes.csv with Git LFS + DVC\"\n",
        "\n",
        "# 5. v2：清洗并版本管理清洗后数据（DVC）\n",
        "!python clean.py data/raw/athletes.csv data/clean/athletes_clean.csv\n",
        "!dvc add data/clean/athletes_clean.csv\n",
        "!git add data/clean/athletes_clean.csv.dvc\n",
        "!git commit -m \"v2: track cleaned athletes.csv with DVC\"\n",
        "\n",
        "# 6. 拆分：v1/v2 版本下各自拆分 train/test\n",
        "!python split.py data/raw/athletes.csv  data/raw/train.csv  data/raw/test.csv\n",
        "!dvc add data/raw/train.csv data/raw/test.csv\n",
        "!git add data/raw/train.csv.dvc data/raw/test.csv.dvc\n",
        "!git commit -m \"v1: split raw into train/test\"\n",
        "\n",
        "!python split.py data/clean/athletes_clean.csv data/clean/train.csv data/clean/test.csv\n",
        "!dvc add data/clean/train.csv data/clean/test.csv\n",
        "!git add data/clean/train.csv.dvc data/clean/test.csv.dvc\n",
        "!git commit -m \"v2: split clean into train/test\"\n",
        "\n",
        "# 7. 推送 DVC 存储\n",
        "!dvc push\n",
        "\n",
        "# 8. EDA、基线&DP模型\n",
        "!python eda.py  data/raw/athletes.csv    v1\n",
        "!python train.py data/raw/train.csv  data/raw/test.csv  models/rf_v1.pkl metrics/metrics_v1.json\n",
        "\n",
        "!python eda.py  data/clean/athletes_clean.csv v2\n",
        "!python train.py data/clean/train.csv data/clean/test.csv models/rf_v2.pkl metrics/metrics_v2.json\n",
        "\n",
        "!pip install -q tensorflow-privacy\n",
        "!python dp_train.py data/clean/train.csv data/clean/test.csv \\\n",
        "    metrics/dp_metrics_v2.json metrics/epsilon_v2.txt\n",
        "\n",
        "# 9. 验证输出\n",
        "!ls models\n",
        "!ls metrics\n",
        "!ls dvc_store"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWP0iQVsdS7T",
        "outputId": "3bdddf35-c589-4bf9-8c6e-d4f1d219bca7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MLops\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Updated git hooks.\n",
            "Git LFS initialized.\n",
            "\u001b[31mERROR\u001b[39m: failed to initiate DVC - '.dvc' exists. Use `-f` to force.\n",
            "\u001b[0mSetting 'local_remote' as a default remote.\n",
            "\u001b[31mERROR\u001b[39m: configuration error - config file error: remote 'local_remote' already exists. Use `-f|--force` to overwrite it.\n",
            "\u001b[0mmv: cannot stat 'athletes.csv': No such file or directory\n",
            "\"data/raw/athletes.csv\" already supported\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  4.17files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 1/1 [00:00<00:00,  2.99file/s{'info': ''}]\n",
            "\n",
            "To track the changes with git, run:\n",
            "\n",
            "\tgit add data/raw/athletes.csv.dvc\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n",
            "\u001b[0mAuthor identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@79445f0fcbd4.(none)')\n",
            "cleaned → data/clean/athletes_clean.csv, shape=(30029, 15)\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/1 [00:00<?, ?file/s{'info': ''}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 1/1 [00:00<00:00,  5.02file/s{'info': ''}]\n",
            "\n",
            "To track the changes with git, run:\n",
            "\n",
            "\tgit add data/clean/athletes_clean.csv.dvc\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n",
            "\u001b[0mAuthor identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@79445f0fcbd4.(none)')\n",
            "split → train:(338404, 27), test:(84602, 27)\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/2 [00:00<?, ?file/s{'info': ' data/raw/train.csv |'}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "100% 1/1 [00:00<00:00,  5.44files/s{'info': ''}]\u001b[A\n",
            "Adding...:  50% 1/2 [00:00<00:00,  2.24file/s{'info': ' data/raw/test.csv |'}] \n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 2/2 [00:00<00:00,  3.08file/s{'info': ''}]                    \n",
            "\n",
            "To track the changes with git, run:\n",
            "\n",
            "\tgit add data/raw/test.csv.dvc data/raw/train.csv.dvc\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n",
            "\u001b[0mAuthor identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@79445f0fcbd4.(none)')\n",
            "split → train:(24023, 15), test:(6006, 15)\n",
            "\u001b[?25l\u001b[32m⠋\u001b[0m Checking graph\n",
            "Adding...:   0% 0/2 [00:00<?, ?file/s{'info': ' data/clean/train.csv |'}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...:  50% 1/2 [00:00<00:00,  4.85file/s{'info': ' data/clean/test.csv |'}]\n",
            "!\u001b[A\n",
            "          |0.00 [00:00,     ?file/s]\u001b[A\n",
            "                                    \u001b[A\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            "                                           \u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s]\u001b[A\n",
            "  0% 0/1 [00:00<?, ?files/s{'info': ''}]\u001b[A\n",
            "Adding...: 100% 2/2 [00:00<00:00,  5.58file/s{'info': ''}]                      \n",
            "\n",
            "To track the changes with git, run:\n",
            "\n",
            "\tgit add data/clean/test.csv.dvc data/clean/train.csv.dvc\n",
            "\n",
            "To enable auto staging, run:\n",
            "\n",
            "\tdvc config core.autostage true\n",
            "\u001b[0mAuthor identity unknown\n",
            "\n",
            "*** Please tell me who you are.\n",
            "\n",
            "Run\n",
            "\n",
            "  git config --global user.email \"you@example.com\"\n",
            "  git config --global user.name \"Your Name\"\n",
            "\n",
            "to set your account's default identity.\n",
            "Omit --global to set the identity only in this repository.\n",
            "\n",
            "fatal: unable to auto-detect email address (got 'root@79445f0fcbd4.(none)')\n",
            "Collecting          |0.00 [00:00,    ?entry/s]\n",
            "Pushing\n",
            "!\u001b[A\n",
            "  0% |          |0/? [00:00<?,    ?files/s]\u001b[A\n",
            " 33% 2/6 [00:00<00:00,  9.33files/s{'info': ''}]\u001b[A\n",
            " 50% 3/6 [00:00<00:00,  8.35files/s{'info': ''}]\u001b[A\n",
            "Pushing\n",
            "Everything is up to date.\n",
            "\u001b[0m--- EDA v1 ---\n",
            "               count  unique  ...       75%           max\n",
            "athlete_id  423003.0     NaN  ...  473188.0      633083.0\n",
            "name          331110  306752  ...       NaN           NaN\n",
            "region        251262      17  ...       NaN           NaN\n",
            "team          155160    4532  ...       NaN           NaN\n",
            "affiliate     241916    9778  ...       NaN           NaN\n",
            "gender        331110       3  ...       NaN           NaN\n",
            "age         331110.0     NaN  ...      37.0         125.0\n",
            "height      159869.0     NaN  ...      72.0     8388607.0\n",
            "weight      229890.0     NaN  ...     192.0       20175.0\n",
            "fran         55426.0     NaN  ...     392.0     8388607.0\n",
            "helen        30279.0     NaN  ...     694.0     8388607.0\n",
            "grace        40745.0     NaN  ...     262.0     8388607.0\n",
            "filthy50     19359.0     NaN  ...    1809.0     8388607.0\n",
            "fgonebad     29738.0     NaN  ...     336.0     8388607.0\n",
            "run400       22246.0     NaN  ...      84.0     8388607.0\n",
            "run5k        36097.0     NaN  ...    1560.0     8388607.0\n",
            "candj       104435.0     NaN  ...     235.0     8388607.0\n",
            "snatch       97280.0     NaN  ...     185.0     8388607.0\n",
            "deadlift    115323.0     NaN  ...     415.0     8388607.0\n",
            "backsq      110517.0     NaN  ...     335.0     8388607.0\n",
            "pullups      50608.0     NaN  ...      39.0  2147483647.0\n",
            "eat            93932      47  ...       NaN           NaN\n",
            "train         105831      83  ...       NaN           NaN\n",
            "background     98945      43  ...       NaN           NaN\n",
            "experience    104936      84  ...       NaN           NaN\n",
            "schedule       97875     134  ...       NaN           NaN\n",
            "howlong       109206      30  ...       NaN           NaN\n",
            "\n",
            "[27 rows x 11 columns]\n",
            "hist saved → v1_hist.png\n",
            "✅ Metrics: {'MAE': 65.44519434628975, 'RMSE': 997.9983316592768, 'R2': 0.3516356838568111}\n",
            "--- EDA v2 ---\n",
            "              count unique  ...     75%     max\n",
            "region        30029     17  ...     NaN     NaN\n",
            "gender        30029      2  ...     NaN     NaN\n",
            "age         30029.0    NaN  ...    37.0    56.0\n",
            "height      30029.0    NaN  ...    72.0    83.0\n",
            "weight      30029.0    NaN  ...   197.0   474.0\n",
            "candj       30029.0    NaN  ...   245.0   390.0\n",
            "snatch      30029.0    NaN  ...   190.0   386.0\n",
            "deadlift    30029.0    NaN  ...   434.0  1000.0\n",
            "backsq      30029.0    NaN  ...   355.0   882.0\n",
            "eat           30029     40  ...     NaN     NaN\n",
            "background    30029     35  ...     NaN     NaN\n",
            "experience    30029     67  ...     NaN     NaN\n",
            "schedule      30029    119  ...     NaN     NaN\n",
            "howlong       30029     25  ...     NaN     NaN\n",
            "total_lift  30029.0    NaN  ...  1224.0  2135.0\n",
            "\n",
            "[15 rows x 11 columns]\n",
            "hist saved → v2_hist.png\n",
            "✅ Metrics: {'MAE': 4.367385947385948, 'RMSE': 13.043748383603997, 'R2': 0.9977849021173308}\n",
            "2025-07-02 20:13:13.640828: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2025-07-02 20:13:13.640885: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2025-07-02 20:13:13.641995: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-07-02 20:13:13.647916: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2025-07-02 20:13:14.697032: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/drive/MyDrive/MLops/dp_train.py\", line 13, in <module>\n",
            "    from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp, get_privacy_spent\n",
            "ModuleNotFoundError: No module named 'tensorflow_privacy.privacy.analysis.rdp_accountant'\n",
            "rf_v1.pkl  rf_v2.pkl\n",
            "metrics_v1.json  metrics_v2.json\n",
            "files\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install -q opacus==1.4.0 torch==2.2.2  # 若已装可跳过\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_absolute_error, r2_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from opacus import PrivacyEngine\n",
        "\n",
        "class CsvRegressionDataset(Dataset):\n",
        "    def __init__(self, path, scaler=None, fit_scaler=False):\n",
        "        df = pd.read_csv(path)\n",
        "\n",
        "        if \"total_lift\" not in df.columns:\n",
        "            df[\"total_lift\"] = df[[\"deadlift\", \"candj\", \"snatch\", \"backsq\"]].sum(axis=1)\n",
        "\n",
        "        X = df[[\"age\", \"weight\", \"height\", \"backsq\"]].astype(np.float32).values\n",
        "        y = df[\"total_lift\"].astype(np.float32).values.reshape(-1, 1)\n",
        "\n",
        "        if fit_scaler:\n",
        "            self.scaler = StandardScaler().fit(X)\n",
        "        else:\n",
        "            self.scaler = scaler\n",
        "        self.X = self.scaler.transform(X)\n",
        "        self.y = y\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.X[idx]), torch.tensor(self.y[idx])\n",
        "\n",
        "TRAIN_CSV = \"/content/drive/MyDrive/MLops/data/clean/train.csv\"\n",
        "TEST_CSV  = \"/content/drive/MyDrive/MLops/data/clean/test.csv\"\n",
        "\n",
        "train_ds = CsvRegressionDataset(TRAIN_CSV, fit_scaler=True)\n",
        "test_ds  = CsvRegressionDataset(TEST_CSV , scaler=train_ds.scaler)\n",
        "\n",
        "batch_size = 128\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, drop_last=True)\n",
        "test_loader  = DataLoader(test_ds , batch_size=batch_size, shuffle=False)\n",
        "\n",
        "class MLP(nn.Module):\n",
        "    def __init__(self, in_dim):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(in_dim, 64),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(64, 1)\n",
        "        )\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MLP(4).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.05)\n",
        "criterion = nn.MSELoss(reduction=\"mean\")\n",
        "\n",
        "noise_multiplier = 1.1\n",
        "max_grad_norm    = 1.0\n",
        "\n",
        "privacy_engine = PrivacyEngine()\n",
        "model, optimizer, train_loader = privacy_engine.make_private(\n",
        "    module          = model,\n",
        "    optimizer       = optimizer,\n",
        "    data_loader     = train_loader,\n",
        "    noise_multiplier= noise_multiplier,\n",
        "    max_grad_norm   = max_grad_norm,\n",
        ")\n",
        "\n",
        "print(f\" Model is now DP.  Noise={noise_multiplier}, Clip={max_grad_norm}\")\n",
        "\n",
        "# ---------- 5. 训练 ----------\n",
        "epochs = 10\n",
        "for epoch in range(1, epochs+1):\n",
        "    model.train()\n",
        "    cum_loss = 0.0\n",
        "    for xb, yb in train_loader:\n",
        "        xb, yb = xb.to(device), yb.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(xb)\n",
        "        loss  = criterion(preds, yb)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        cum_loss += loss.item() * xb.size(0)\n",
        "    print(f\"Epoch {epoch}/{epochs}  |  train-MSE = {cum_loss/len(train_ds):.2f}\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y_true, y_pred = [], []\n",
        "    for xb, yb in test_loader:\n",
        "        xb = xb.to(device)\n",
        "        y_pred.append(model(xb).cpu())\n",
        "        y_true.append(yb)\n",
        "    y_true = torch.vstack(y_true).squeeze().numpy()\n",
        "    y_pred = torch.vstack(y_pred).squeeze().numpy()\n",
        "\n",
        "mae = mean_absolute_error(y_true, y_pred)\n",
        "r2  = r2_score(y_true, y_pred)\n",
        "print(f\"\\n  Test MAE = {mae:.2f} | R² = {r2:.3f}\")\n",
        "\n",
        "\n",
        "delta    = 1 / len(train_ds)\n",
        "epsilon  = privacy_engine.get_epsilon(delta)\n",
        "print(f\"\\n  DP guarantee: ε = {epsilon:.3f}  (δ = {delta:.2e})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NvK6HYF4xr6r",
        "outputId": "a98d1aad-56e0-4a83-c0af-436daa986d8c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.8/224.8 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m755.6/755.6 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.9/167.9 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.21.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\n",
            "torchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/opacus/privacy_engine.py:96: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
            "  >>> model = MyCustomModel()\n",
            "WARNING:opacus.data_loader:Ignoring drop_last as it is not compatible with DPDataLoader.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Model is now DP.  Noise=1.1, Clip=1.0\n",
            "Epoch 1/10  |  train-MSE = 272453.96\n",
            "Epoch 2/10  |  train-MSE = 4839.33\n",
            "Epoch 3/10  |  train-MSE = 4421.95\n",
            "Epoch 4/10  |  train-MSE = 4452.00\n",
            "Epoch 5/10  |  train-MSE = 4421.70\n",
            "Epoch 6/10  |  train-MSE = 4300.91\n",
            "Epoch 7/10  |  train-MSE = 4319.62\n",
            "Epoch 8/10  |  train-MSE = 4385.31\n",
            "Epoch 9/10  |  train-MSE = 4480.29\n",
            "Epoch 10/10  |  train-MSE = 4399.36\n",
            "\n",
            "🔎  Test MAE = 49.68 | R² = 0.943\n",
            "\n",
            "  DP guarantee: ε = 0.947  (δ = 4.16e-05)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AfOzgu6dtxfp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}